# 机器学习中什么是过拟合？

> 原文：<https://dev.to/mrm8488/what-is-overfitting-in-machine-learning--1c11>

[![Image](../Images/99d40d346d6869f1ef4c8c367519db18.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--8Epq2nAB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/lne97v0pst5qjp1u4oup.png)

当你进入机器学习世界时，过度适应是你必须面对的关键问题之一。

理论上说，当你在训练集上有 100%或几乎 100%的预测准确性，并且当你根据看不见的数据(验证/测试集)检查你的模型时，预测准确性离训练很远，就会发生**过度拟合**。

换句话说，当您的预测模型在样本/数据大小/噪声方面过于复杂时，就会发生过度拟合。

这是什么意思？这意味着你的算法记住了样本的训练实例。

那么，为什么不好呢？就像在现实生活中，当你有一次历史考试时，你只是记忆(用心学习)书中关于美国内战的内容。如果在考试中你以同样的方式/顺序被问到你已经记住的问题，你的分数可能是 10/10。但是如果问题类似于“告诉我美国内战*的社会背景”，你会对你的老师说:“我的历史课本里没有这个问题！问题是:美国内战...仅此而已！!"啊哈，你已经背熟了，你不能回答这个问题。*

 *再比如:我们如何学习乘法？背诵乘法表。但是当我们必须乘以 12×45 时会发生什么呢？没有 12 人桌，也没有 45 人桌。所以，我们应该知道 N 乘以 M 等于 M 的 N 倍。

机器学习算法以类似的方式工作。当它用心学习时，它不能很好地概括 T1。这是主要目标，**以最佳方式**进行概括，对新数据进行高精度预测(当然，这些新数据很少与训练集数据相同)。

PD:下一个帖子将是关于如何**解决过度拟合**。*