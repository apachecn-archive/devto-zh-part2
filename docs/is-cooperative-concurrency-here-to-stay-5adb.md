# 协作并发会一直存在吗？

> 原文：<https://dev.to/nestedsoftware/is-cooperative-concurrency-here-to-stay-5adb>

## 简介

在过去的十年中，协作并发在 Web 应用程序中的势头越来越大。 [Node.js](https://nodejs.org/en/about/) 使用。它已经在 Python 的 [asyncio](https://docs.python.org/3/library/asyncio.html) 中实现，并在许多不同的编程语言和框架中使用。在本文中，我将讨论这种并发性的利与弊，并对其未来进行一些推测。

软件中处理多任务有两种方式:协作式多任务和抢占式多任务。

## 抢占式多任务:多线程

直到最近，Web 应用程序的并发性主要是通过使用线程的抢占式多任务处理来实现的:每个请求都被分配一个操作系统线程。当请求完成时，线程可以被释放回池中。

对于 Web 应用程序，线程有一些很好的属性:

*   线程是抢占式的，所以如果一个给定的线程花费大量时间使用 CPU，其他线程仍然会得到服务。
*   线程可以并行分配给不同的 CPU 或 CPU 内核，这意味着如果两个并发请求都使用大量 CPU，多线程将提供显著的加速。

如果线程如此伟大，那么为什么像服务器上的 Node.js 这样的技术会越来越流行呢？毕竟 Node 采用的是协作多任务模式。

## 合作多任务:一点历史

什么是协作式多任务处理？这意味着每个任务都在事件循环的上下文中运行。事件循环让每个任务轮流使用 CPU。然而，将控制释放回事件循环是每个任务的工作。如果一个任务不能释放控制，那就没办法了。

Web 应用程序的协作多任务在某些方面让我们回到了过去。Windows 3.1 和 Mac Os 9 都支持协同多任务处理。协作式多任务处理的一个缺点是它使整个系统变得脆弱。单个应用程序很容易使整个操作系统崩溃。

到 21 世纪初，微软(我相信是从 Win 95 开始)和苹果(OS X)都拥有了抢占式多任务处理:操作系统会给每个进程分配时间片。它在每个时间片后自动中断(即抢占)每个应用程序。这样，给定的应用程序可能会冻结或崩溃，但这不会阻止系统作为一个整体工作。

## 无多线程并发

在 Node.js 这样的系统中，方法类似于 Windows 3.1 和 Mac OS 9。Node.js 在 JavaScript 事件循环中运行。所有请求都在一个线程中处理。节点将控制权交给队列中的请求。每个请求都会做一些工作，然后将控制返回给事件循环，以便其他请求可以继续进行。

这种方法肯定有一些缺点:如果一段代码需要在 CPU 上进行大量的处理，或者由于其他原因而失败，这不仅会降低特定请求的处理速度，还会延迟当前正在处理的所有其他请求。*应用的每个用户都会经历减速*。这是一个相当大的缺点！

然而，协作并发已经变得相当流行。这是为什么呢？我认为主要有两个原因:

1.  操作系统从一个线程到另一个线程的上下文切换需要一定的时间。时间并不多(微秒级)，但是因为它确实涉及到与操作系统的对话，所以比在一个线程中从一个任务切换到另一个任务要慢。

2.  随着同时访问 Web 应用程序的用户数量的增加，使用的线程数量也在增加。一个典型的 linux 系统应该能够非常容易地处理成千上万个线程。但是，如果线程的数量足够多，就会开始影响应用程序以及操作系统本身的性能。一旦我们真的达到了这个极限，一台计算机已经不够了，我们需要投资更多的硬件。

## 比较

在寻找这两种方法之间的简单比较时，我认为我在 Apache 和 NGINX 在处理静态内容时的性能差异方面找到了一个有趣的候选者。Apache 基本上仍然使用线程来服务请求，而在 NGINX 中，标准设置是为每个 CPU 内核分配一个进程。除此之外，事件循环在每个进程中运行，并在内部处理分配给该进程的所有请求。差异非常显著。根据这个[分析](https://www.eschrade.com/page/performance-of-apache-2-4-with-the-event-mpm-compared-to-nginx/)，和[这个](http://www.speedemy.com/apache-vs-nginx-2015/)，NGINX 至少快一倍。

## 讨论

如果我们要选择是使用 NGINX 还是 Apache 来服务静态页面，这个选择非常简单，因为它们是如何实现的细节并不重要。当涉及到我们自己的软件架构选择时，就有点困难了。很明显，当涉及到 I/O 相关任务的性能时，合作方法可以带来好处。然而，这确实需要我们格外小心我们的代码:

*   所有 I/O 必须是非阻塞的。
*   受 CPU 限制的处理可能必须分解成独立的块，以便其他任务可以在其间取得进展。或者，CPU 绑定的任务可以被发送到单独的线程中运行。

最后，对于我们自己的应用程序来说，这可能是值得的吗？我认为协作式并发的价值随着规模的扩大而增加。对于一个有几千名并发用户的相对较小的应用程序，我不认为它会有什么不同。然而，随着我们的规模扩大到越来越多的用户，我们的硬件成本将开始上升。最终，当我们接触到像谷歌、亚马逊、微软这样的大玩家时，通过提高每台机器的效率，从数据中心维护成本中削减几个百分点，可以节省数百万美元。在这种情况下，即使要花更多的钱在软件的开发和维护上，净收益也是值得的。

我在本文前面提到旧的操作系统的原因是为了强调一点，当有许多第三方依赖时，协作式多任务处理做得不好，例如用户可能在操作系统上安装的所有应用程序。同样，我们越想在应用程序中使用各种各样的库和框架，协作并发就变得越令人担忧:至少其中一个库和框架行为不良并导致整个应用程序崩溃的可能性就会增加。

我真的不知道，但我猜想 NGINX 代码相对来说很少依赖外部依赖。结合 Web 服务器所做的简单工作，我认为我们可以看到协作并发的使用对于该用例是如何有意义的:NGINX 是一个专门的、高度调整的软件。

最后，每个软件项目都必须自己决定选择哪种并发模型。我认为认识到这两种方法都有潜在的优点和缺点是值得的。这不是选择绝对“最佳”解决方案的问题。相反，这是一个权衡各种利弊并将其应用于当前问题的问题。

## 是要留在这里吗？

考虑到它确实有缺点，我想知道协作并发是否会像它从操作系统中消失一样最终从服务器端编程中消失。也许随着硬件变得更好，线程工作方式的改进，性能上的差异会再次变小。

另一方面，如此多的计算现在发生在云中的事实意味着跨大量并发连接的伸缩将继续是一个优先事项。对于在用户机器上本地运行的应用程序来说，这不是问题。这可能是一个根本性的区别，可以解释为什么协同并发从 pc 机上消失了，但在 Web 和 Internet 应用程序中却变得强大了。

我确实认为，在可预见的未来，在获得尽可能多的请求/秒至关重要的情况下，或者在水平可伸缩性(同时支持更多用户)非常重要的情况下，这种方法可能会继续存在。

## 补遗:什么是非阻塞 I/O？

我有这样的印象，术语“非阻塞”有时会有点混乱。它的意思很简单。假设我们有一个检索数据的函数。当我们调用函数时，数据可能可用，也可能不可用。

如果我们的函数是非阻塞的，这意味着无论如何它都会立即返回。如果数据可用，我们的函数将返回所需的数据。如果数据不可用，那么它只会返回一个类似于`NOT_READY`的状态，但是不管怎样，它都会返回。另一方面，阻塞函数可以阻塞当前线程，并迫使它等待数据可用。对于协作并发，我们必须确保所有对 I/O 的调用都是非阻塞的，因为我们的整个事件循环都依赖于此。

处理非阻塞 I/O 的一种方法是保持轮询，直到我们想要的数据可用。例如，参见类似于[选择](https://en.wikipedia.org/wiki/Select_(Unix))函数的内容。Node.js 中使用的另一种方法是向非阻塞调用提供回调。数据变得可用后，事件循环调用回调，请求可以从那里继续进行(同时，非阻塞调用返回，事件循环继续处理其他请求)。在后一种情况下，在幕后仍然有一个最终的循环轮询，但是使用 Node.js 的程序员不必担心它是如何实现的。

我们经常在协作并发的环境中听到“非阻塞”的说法，但事实并非如此。比如 Java 的[原子变量](https://docs.oracle.com/javase/tutorial/essential/concurrency/atomicvars.html)允许多个线程无阻塞地访问共享数据。他们通过尝试在循环中执行原子操作来实现这一点:如果操作成功，那太好了。如果失败了，那么我们必须继续尝试。在多线程应用程序的上下文中，轮询也是同样的想法。另一方面，对锁进行同步是阻塞的:想要修改受锁保护的数据的线程必须阻塞，直到锁消失。

## 附录:I/O 限制与 CPU 限制

由于协作并发意味着在一个线程中处理多个请求，因此在任何给定时间都只有一个任务在使用 CPU，所以当应用程序逻辑受 I/O 限制时，协作并发工作得最好。这意味着一个给定的请求可能需要一点 CPU 时间，但是大部分时间实际上将用于等待 I/O:访问数据库、连接到远程服务等等。从 CPU 的角度来看，I/O 会花费很长时间。当一个特定的请求正在等待 I/O 时，它可以将控制权交还给事件循环，以便其他请求可以继续被处理。只要所有的请求都放弃控制来频繁地等待 I/O，整个系统就应该平稳地运行。许多常用的应用程序——电子邮件、在线购物、社交网络——都是关于在某个地方加载或发送数据的。它们是这种并发性的绝佳候选。如果我们的应用程序逻辑是 CPU 受限的，也就是说，每个请求将大部分时间用于实际处理，而不是等待 I/O，那么这种模型可能不是一个好主意。