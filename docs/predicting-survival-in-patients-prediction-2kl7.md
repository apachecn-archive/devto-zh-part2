# 预测患者存活率:预测

> 原文：<https://dev.to/ugis22/predicting-survival-in-patients-prediction-2kl7>

[![](../Images/87d008be45af321f49768cabbf267a22.png)T2】](https://cdn-images-1.medium.com/max/1024/1*vpaLyTILKqRSQXqIu6BT7w.jpeg)

#### 构建我的第一个数据科学项目

获得数据后，很容易立即尝试拟合几个模型并评估它们的性能。然而，首先要做的是探索性数据分析(EDA)，它允许我们探索数据的结构，并理解控制变量的关系。任何 EDA 都应该包括创建和分析几个图，并创建汇总统计数据，以考虑我们的数据集中存在的模式。

*如果你想知道，我是如何为这个特定的项目执行 EDA 的，你可以阅读这个* [*以前的帖子*](https://dev.to/ugis22/predicting-survival-in-patients-exploratory-analysis-3k77-temp-slug-5133306) *。*

从这个项目的 EDA 中，我们了解了数据集的一些重要特性。首先，它不会遭受*的类不平衡，即当一个类中的观察总数明显低于另一个类中的观察总数时发生的类不平衡。此外，我们的一些变量显示出偏斜度，在对它们进行对数变换后偏斜度被固定，并且没有变量

显示出与其他变量的完美线性关系，尽管在其中一些变量中，我们可以观察到相互作用的趋势。*

 *### **机器学习预测**

执行机器学习时要做出的一个主要决定是选择适合我们正在处理的当前问题的适当算法。

**监督学习**指的是从一个带标签的训练数据集中推断出一个函数的任务。我们将模型拟合到带标签的训练集，主要目标是找到最佳参数，这些参数将预测测试数据集中包含的新示例的未知标签。有两种主要类型的监督学习:回归，其中我们希望预测一个实数标签，以及分类，其中我们希望预测一个分类标签。

在我们的例子中，我们有一个带标签的数据集，我们想使用分类算法在分类值 0 和 1 中找到标签。

我们可以找到许多分类监督学习算法，一些简单但有效，如线性分类器或逻辑回归，另一些更复杂但功能强大，如决策树和 k-means。

在这种情况下，我们会选择**随机森林**算法。随机森林是最常用的机器学习算法之一，因为它非常简单、灵活和易于使用，但产生可靠的结果。

简而言之，随机森林创建多个决策树的“T0”森林，并集合它们以获得更准确的预测。随机森林相对于决策树的优势在于，单个模型的组合改善了整体结果，并且通过从特征的随机子集创建更小的树来防止过度拟合。

因此，我们将首先从 scikit 加载包——了解我们需要执行随机森林，然后还要评估模型。我们还将使用 0 或 1 或 NaN 替换分类值，并将所有变量转换为浮点型，并对变量进行对数转换以固定偏斜度，就像我们在 EDA 中所做的那样。我们将再次检查每个变量中缺失值的总数:*