# 将备份流式传输到 S3

> 原文:[https://dev.to/ferricoxide/streamed-backups-to-s3-41m7](https://dev.to/ferricoxide/streamed-backups-to-s3-41m7)

## [](#introductionbackground)简介/背景

许多 AWS 的潜在用户都是从传统的托管背景来到 AWS 的。很多时候，当迁移到 AWS 时，人们会问这样一个问题:“当我不再能够访问我的企业备份工具时，我该如何备份我的数据？”如果不是，这是潜在的 AWS 用户*应该*问的问题。

AWS 提供了许多存储选项。每个选项都有针对其优化的用例。每一种都有性能、功能和价格权衡的组合(参见[我的文档](https://thjones2.blogspot.com/p/there-are-about-bazillion-web-sites.html)中对这些权衡的快速总结)。成本最低——因此，对于备份相关活动的典型数据保留使用情形来说，通常最有吸引力——是 S3。此外，在 S3，有适合不同类型备份需求的定价/功能级别(以下列表按价格从高到低排列):

*   如果需要频繁执行完整或部分恢复，S3 标准层可能是最佳选择
*   如果恢复频率几乎是“从不”，但如果确实需要执行恢复，则需要快速恢复，并且管理备份的策略要求最长 30 天的可恢复性窗口，则最佳选择可能是 S3 非频繁访问(IA)层。
*   如果除了法律法规遵从性功能之外，通常不需要恢复，或者备份的恢复时间目标(RTO)允许等待数小时数据变得不可用，则 S3 冰川层可能是最佳选择。

此外，如果项目的备份需求跨越前面列表中的使用模式，可以创建数据生命周期策略，根据时间阈值将数据从较高成本层移动到较低成本层。为了防止对不再有用的数据进行计费，生命周期策略还可以包括到期时间。达到设定的过期时间的数据将被 AWS 删除，过期数据的相关费用将停止。

有几种方法可以将备份数据导入 S3:

*   *拷贝:*最简单的，也可能是最广为人知的，就是将数据从主机拷贝到 S3 存储桶中。拷贝到 S3 的每个磁盘文件在 S3 都是可单独下载的文件。复制操作可以是迭代的或递归的。如果复制操作采用递归复制的形式，文件之间的基本位置关系将被保留(尽管像硬链接或软链接这样的东西会被转换成给定文件的多个副本)。虽然这种方法很简单，但它包括文件系统元数据的丢失——不仅仅是前面提到的链接式文件数据的丢失，还有所有权、权限、MAC 标签等的丢失。
*   “同步”方法同样简单。像基本拷贝一样，磁盘上拷贝到 S3 的每个文件在 S3 都是可单独下载的文件。同步操作本质上是递归的。此外，如果在 S3 内的给定位置存在文件的相同副本，则仅当要复制的文件不同时，同步操作才会覆盖 S3 托管的文件。这为增量式备份提供了很好的支持。与基本的拷贝到 S3 方法一样，这种方法会导致文件链接和其他文件系统元数据的丢失。

> 注意:如果使用这种方法，打开 bucket-versioning 以确保上传文件的每个版本都得到保留可能是个好主意。这允许恢复操作恢复备份文件的给定时间点版本。

*   *流式复制:*这种方法最不为人所知。但是，可以利用这种方法来克服文件系统元数据丢失的问题。如果流至 S3 操作包括内联数据封装操作(例如，通过`tar`实用程序传输流)，文件系统元数据将被保留。

> 注意:通过封装保存元数据的代价是封装的对象对 S3 来说(大部分)是不透明的。因此，实际上没有一种好的(直接的)方法来模拟增量备份操作。

## [](#technical-implementation)技术实现

正如本文的标题所示，本文的技术实现重点是到 S3 的流式备份。

大多数 S3 用户都知道它的静态文件复制选项。也就是将文件从 EC2 实例直接复制到 S3。大多数这样的用户，当他们想要在 EC2 中存储文件并需要保留文件系统元数据时，要么使用像 [s3fs](https://github.com/s3fs-fuse/s3fs-fuse) 这样的东西，要么进行分阶段封装。

前者允许您将 S3 视为一个本地文件系统。然而，由于各种原因，许多组织不习惯使用基于 FUSE 的文件系统实现——尤其是开源项目(通常是因为担心出现问题时的支持)。

后者意味着使用归档工具创建数据的预打包拷贝，首先作为完整文件转移到磁盘，然后拷贝到 S3。常见的归档工具包括 Linux 磁带归档工具(`tar`)、`cpio`甚至`mkisofs` / `genisoimage`。但是，如果归档工具支持从 STDIN 读取和/或向 STDOUT 写入，那么该工具可以使用 S3 的流复制功能直接在 S3 创建归档。

备份的最佳做法是确保目标数据集处于一致状态。通常，这意味着要归档的数据是不变的。这可以通过暂停文件系统来完成...或者拍摄文件系统的快照并备份快照。将使用 LVM 快照来说明如何对实时文件系统(如用于托管操作系统的文件系统)进行一致备份。)

> 注意:此图假设要备份的文件系统构建在 LVM 之上。如果文件系统构建在一个空的(EBS 提供的)设备上，则需要先停止文件系统，然后才能将其一致地传输到 S3。

高级过程如下:

1.  创建托管要备份的文件系统的逻辑卷的快照(请注意，LVM 在创建快照之前会发出一个`fsfreeze`操作:这将在创建快照之前刷新所有挂起的 I/o，从而确保生成的快照处于一致状态)。可以选择精简或静态大小的快照(精简快照在对同一卷组内的多个卷进行快照时特别有用，因为人们不太需要担心快照卷的大小规格是否正确)。
2.  装载快照
3.  使用归档工具将文件系统数据流式传输到标准输出
4.  将流通过管道传输到 S3 的`cp`工具，指定从流中读取并写入 S3 的对象名
5.  卸载快照
6.  删除快照
7.  使用 S3 的`cp`工具验证备份，指定写入一个流，然后使用原始归档工具从标准输入读取的功能读取该流。如果存档工具有一个“测试”模式，使用它；如果没有，很可能将/dev/null 指定为它的输出目标。

对于上述内容的基本自动化实现，请参见链接到的[工具](https://drive.google.com/file/d/12Al0sLynNCbTU4n3eoW-JrgVgh2mS-2T/view?usp=sharing)。注意，这个工具是“哑”的:它假设所有托管文件系统的*逻辑卷都应该被备份。唯一需要的参数是归档到的 S3 存储桶的名称。该脚本只做非常基本的“飞行前”检查:*

*   确保在脚本继承的`PATH` env 中找到 AWS CLI。
*   请确保 AWS IAM 实例角色已附加到实例，或者在脚本的执行环境中定义了 IAM 用户角色(`${HOME}/.aws/credential`文件当前不支持)。不会尝试确保实例或 IAM 用户角色有足够的权限写入选定的 S3 存储桶
*   确保已经传递了一个 bucket-name，但没有检查其有效性。

一旦预飞行通过:脚本将尝试快照托管文件系统的所有卷；在`/mnt`层级下挂载快照—重新创建原始卷的挂载位置，但以`/mnt`为根；使用`tar`实用程序将待归档的数据封装并流式传输到 s3 实用程序；使用 S3 `cp`实用程序将`tar`的流式、封装输出写入命名为 S3 木桶的`/Backups/`文件夹。一旦 S3 cp 应用工具正确关闭数据流，脚本将卸载并删除之前创建的快照。

## [](#alternatives)替代品

如前所述，对于不驻留在 LVM2 逻辑卷上的文件系统，可以执行与上述类似的操作。但是，这样做要么需要不同的方法来为备份集创建一致的状态，要么备份潜在的不一致数据(甚至可能完全丢失“运行中”的数据)。

EBS 具有创建写入时拷贝快照的本机能力。然而，EBS 卷的快照功能通常与操作系统“暂停”文件系统的能力无关。可以使用一个工具——比如在 [LxEBSbackups](https://github.com/plus3it/LxEBSbackups) 项目中的工具——来协调文件系统的暂停，以便 EBS 快照可以创建数据的一致副本(然后在 EBS 快照启动后立即取消暂停文件系统)。

用户可以将数据“按原样”保留在 EBS 快照中，也可以将快照装载到 EC2，然后对 S3 执行流式归档操作。前者有低努力的价值。后者的好处是将数据存储到价格较低的层(即使 S3 标准卷也比 EBS 卷的快照便宜)，并允许将备份的数据置于 S3 生命周期策略下。

([原始发布位置](https://thjones2.blogspot.com/2018/05/streamed-backups-to-s3.html))