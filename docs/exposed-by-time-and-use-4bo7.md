# 因时间和使用而暴露

> 原文：<https://dev.to/ferricoxide/exposed-by-time-and-use-4bo7>

去年，我接手了一个既复杂又紧急的项目。更糟糕的是，出于慈善目的，这个项目并没有被很好地指定。基本上是，“我们需要你自动化这六项服务的部署，我们需要在三十天内有可演示的东西”。

自然，从安装或管理的角度来看，这六个服务是我从未使用过的。因此，围绕如何最好地自动化事情，有一个学习曲线的*位*,没有“这是期望的最终状态”或其他相关细节的帮助。他们真正知道的是:

*   自动部署到 AWS 中
*   确保它在我们定制/强化的版本上工作
*   确保它备份自己以防事情发生
*   ***出发！*T3】**

我尝试解决这个问题。我赶上了最后期限。显然，结果并不完全是“最优的”——尤其是从“把它交给别人来维护”的角度来看。自然地，在我将初始功能移交给请求者之后，他们有几个星期没有联系。

当他们*终于*回复时，是为了让我知道最后期限已经被*延长了几个*月。所以，我选择利用这段时间让外行人更容易使用自动化。这在这里几乎无关紧要，只是更多的“背景”。

无论如何，我们现在距离最初的紧急任务已经过去了将近一年半的时间。而且，虽然我已经提高了自动化的易用性(它已经被移交给其他人进行日常护理和喂养)，但许多潜在的*逻辑*还没有被重新审视。

在这样的时间跨度内，时间往往会暴露给定解决方案的缺点。最近，他们试图对其中一项服务进行并行升级，并发现解决方案的数据移动部分会导致构建超时。事实证明，正在备份的数据集(以及作为自动化迁移过程的一部分从中恢复的数据集)的大小已经呈爆炸式增长。我将备份设置为增量操作，因此原始传输时间的增加被隐藏了。

增量备份只需要几分钟；但是，数据集的恢复需要 35 分钟以上。构建自动化被设置为超时 15 分钟(在服务部署的早期，类似的操作需要 3-7 分钟),因此，第一步是调整自动化的超时，以适应新的恢复时间现实。第二步是调查为什么恢复*如此之慢*。

我选择的快速 n 脏备份方法是一个简单的`s3 sync --delete /<APPLICATION_HOME_DIR>/ s3://<BUCKET>/<FOLDER>`。这是将目录`/<APPLICATION_HOME_DIR>/`的内容“清扫”到 S3 的非常简单的方法。而且，由于 S3 的`sync`方法默认为增量，cron 管理的备份每天花费的时间与一年多前一样多。

关于 S3 及其[传输性能](https://aws.amazon.com/blogs/aws/amazon-s3-performance-tips-tricks-seattle-hiring-event/)的有趣事实:如果你上传的对象具有高度通用性的键，传输性能将变得糟糕透顶。

你可能会问我为什么提到“密钥”,因为我没有提到加密。S3 是一种基于对象的文件系统，没有传统的面向主机的存储的分层布局。如果我从面向主机的存储中取出一个文件，并使用 S3 CLI 应用工具通过该文件到 S3 的完全限定路径名来拷贝该文件，则在 S3 创建的对象将如下所示:

> ```
> <FULLY>/<QUALIFIED>/<PATH>/<FILE> 
> ```

其中，“`<FILE>`”是存储在 S3 的对象名，而“`<FULLY>/<QUALIFIED>/<PATH>`”是该文件的关键字。如果您有几千个具有相同或足够相似的“`<FULLY>/<QUALIFIED>/<PATH>`”值的对象，您将遇到前面提到的“*传输性能将变得糟糕透顶的*”问题。

我们非常肯定遇到了那个问题。**难**。正在讨论的数据集(目前)的大小小于 11GiB。正在备份的实例的[预期吞吐量](https://cloudonaut.io/ec2-network-performance-cheat-sheet/)约为 0.45Gbps 的持续网络吞吐量。因此，我们*期望*该数据集只需要几分钟就能传输完毕。但是，如上所述，这样做需要 35 分钟以上。

那么，如何修复呢？一个更简单的方法是[将你的备份](https://thjones2.blogspot.com/2018/05/streamed-backups-to-s3.html)传输到一个文件中。一系列快速的基准测试表明，这样做可以将传输时间从 35 分钟以上缩短到 5 分钟以下。类似地，如果遍历数据集中的所有文件，并使用随机文件名(并将“真正的”完全限定路径设置为文件的属性/标签)或简单地反转路径名(执行类似于`S3NAME=$( echo "${REAL_PATHNAME} | perl -lne 'print join "/", reverse split/\//;') )`的操作并存储*的*，将文件单独复制到 S3，那么您的性能会显著提高。

我可能会选择这三种方法中的一种...一旦我有足够的连续时间来分配重新设计备份和恢复/重建方法。每一个都有需要平衡的权衡——特别是在避免复制已经存在于目的地的源数据方面。