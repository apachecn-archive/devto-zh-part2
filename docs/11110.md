# 单词矢量化手套

> 原文:[https://dev.to/japneet121/glove-for-word-vectorization-1ak0](https://dev.to/japneet121/glove-for-word-vectorization-1ak0)

[![](../Images/4e590782734b71e603aa4baffe8f6271.png)T2】](https://3.bp.blogspot.com/-U8Cjp06jluc/Wt7rRjQ3KKI/AAAAAAAAbjE/DGD3_b3UOHYyUjsA4DbxJsxXgqG6jX_YwCLcBGAs/s1600/Text-to-vector-3_normal.png)

## 什么是爱

GloVe 代表单词表示的全局向量。它是由斯坦福大学开发的一种无监督学习算法，用于通过从语料库聚集全局单词-单词共现矩阵来生成单词嵌入。由此产生的嵌入显示了向量空间中单词的有趣的线性子结构。

线性子结构的例子有:

[![](../Images/4c7ec3da61bfb5bf0ecfd0b4b4119650.png)T2】](https://3.bp.blogspot.com/-TcJsh6VB75E/Wt7xk0VBQxI/AAAAAAAAbjY/7_pS22MdugQBQ9vOBJUV2hsm2b9bcVbZQCEwYBhgL/s1600/vec2.jpg)

[![](../Images/0d5c8cd2abcff65b4e4481aa7c1de975.png)T2】](https://4.bp.blogspot.com/-8v4NzcL-vvs/Wt7xk6PbLZI/AAAAAAAAbjU/XBmQq_Jnb-UgW6FeoSZ6kQdrejwdjNAhQCLcBGAs/s1600/vec1.jpg)

这些结果令人印象深刻。这种类型的表示在许多机器学习算法中非常有用。

要阅读更多关于单词矢量化的内容，你可以阅读我的另一篇文章。

在这篇博文中，我们将学习 python 中 GloVe 的实现。那么，我们开始吧。

## 让我们创建嵌入

### 安装 Glove-Python

The GloVe is implementation in python is available in library **glove-python.**

```
pip install glove_python

```

### 文本预处理

在这一步，我们将对文本进行预处理，比如去除停用词，对单词进行词条化等。您可以根据自己的需求执行不同的步骤。我将使用 nltk 停用词语料库来移除停用词，并使用 nltk 词词条化来查找词条。为了使用 nltk 语料库，您需要使用以下命令下载它。**下载语料库**

```
import nltk
nltk.download()
#this will open a GUI from which you can download the corpus

```

**输入初始化**

```
#list of sentences to be vectorized
lines=["Hello this is a tutorial on how to convert the word in an integer format",
"this is a beautiful day","Jack is going to office"]
```

**去除停用词** **```
from nltk.corpus import stopwords
stop_words=set(stopwords.words('english'))

lines_without_stopwords=[]
#stop words contain the set of stop words
for line in lines:
 temp_line=[]
 for word in lines:
  if word not in stop_words:
   temp_line.append (word)
 string=' '
 lines_without_stopwords.append(string.join(temp_line))

lines=lines_without_stopwords

```

****词汇化**

```
#import WordNet Lemmatizer from nltk
from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()

lines_with_lemmas=[]
#stop words contain the set of stop words
for line in lines:
 temp_line=[]
 for word in lines:
  temp_line.append (wordnet_lemmatizer.lemmatize(word))
 string=' '
 lines_with_lemmas.append(string.join(temp_line))
lines=lines_with_lemmas

```

现在我们已经完成了文本的基本预处理。任何其他预处理工作都可以类似地完成。

### 准备输入

### 我们有一个行数组形式的输入。为了让模型处理数据，我们需要将输入转换为单词数组(:\)。

 **```
#importing the glove library
from glove import Corpus, Glove

# creating a corpus object
corpus = Corpus() 

#training the corpus to generate the co occurence matrix which is used in GloVe
corpus.fit(lines, window=10)

#creating a Glove object which will use the matrix created in the above lines to create embeddings
#We can set the learning rate as it uses Gradient Descent and number of components

glove = Glove(no_components=5, learning_rate=0.05)

glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)
glove.add_dictionary(corpus.dictionary)
glove.save('glove.model')
```

Creating a glove model uses the co-occurrence matrix generated by the Corpus object to create the embeddings. The **corpus.fit** takes two arguments:

*   线条——这是我们在预处理后创建的 2D 数组
*   窗口-这是两个单词之间的距离，algo 应该考虑找到它们之间的一些关系

Parameters of Glove:

*   组件数量-这是手套生成的输出向量的尺寸
*   learning_rate - Algo 使用梯度下降，因此学习速率定义了算法达到最小值的速率(速率越低，学习所需的时间越长，但达到最小值的时间越长)

Parameters of glove.fit :

*   共现矩阵:词-词共现矩阵
*   时期:这定义了算法通过数据集的次数
*   线程数:算法运行时使用的线程数

After the training glove object has the word vectors for the lines we have provided. But the dictionary still resides in the corpus object. We need to add the dictionary to the glove object to make it complete.

```
glove.add_dictionary(corpus.dictionary)

```

这一行在 glove 对象中做字典添加。之后，对象就可以为您提供嵌入了。

```
print glove.word_vectors[glove.dictionary['samsung']]
OUTPUT:

```
[ 0.04521741  0.02455266 -0.06374787 -0.07107575  0.04608054]
```

```

这将打印单词“samsung”的嵌入内容。

## 尾注

我们已经学习了如何为文本数据生成向量，这对创建许多机器学习模型和技术非常有用，如 SVM、KNN、K-Means、逻辑分类器、情感分析、文档分类等。

可以在斯坦福大学的网站上了解更多关于这款手套的信息。******