# AI 缺什么？

> 原文:[https://dev.to/cheetah100/what-is-ai-missing-5j](https://dev.to/cheetah100/what-is-ai-missing-5j)

奇点的论点，实现人工智能，主要是基于一个与技术进步速度有关的统计论点。正如我们可以根据统计数据预测 1 月份将比 7 月份更热，但不能肯定地说 1 月份的实际天气细节一样，我们可以在一定程度上肯定人工智能的最新进展，但对未来技术的具体细节却知之甚少。就像天气一样，你需要非常接近才能开始预测技术的细节。

我们已经足够接近奇点了，现在我觉得我们可以开始识别人类和机器智能之间的差距了。机器现在能够玩棋盘游戏，在嘈杂的环境中识别语音，并且比人类更好地识别图像中的特征。他们可以相当准确地在不同语言之间进行翻译。这些事情不是通过能够编写惊人算法的计算机“神童”来实现的，而是通过学习神经网络的应用来实现的。

人工智能研究人员已经走了很多路，但深度学习神经网络方法近年来已经彻底失败。有一种误解，认为这些系统没有表现出像人类一样的智力的原因是因为它们的网络中还没有足够数量的神经元，或者连接的数量不够。实现一般智能仅仅是给神经网络一个更大的机器来运行吗？

正如提高 CPU 速度或增加 RAM 大小不是机器智能的答案一样，神经网络的大小或速度也不是。最近展示了一台 Nvidia 机器，它能够以每秒数千的速度识别图像中的物体和人脸。没有人能做这样的事情，然而我们被期望相信处理能力是人类智力水平的障碍？如果神经元的数量至关重要，那么为什么一些大脑大部分缺失的人仍然能够正常工作呢？小哺乳动物如何在我们神经元数量少得多的 AI 中拥有我们想要的特征？

那么我们遗漏了什么？在我看来，核心差异都是相关的。意识、情感、意图、学习和记忆。目前人工智能领域的热门话题之一是人工智能安全，即控制机器的行为和意图。目前，人工神经网络不具有自我确定的意图。在某种程度上，他们有任何意图，这完全由人类决定。无论是在来自阿富汗的视频中搜索恐怖分子，还是在 facebook 上找到最好的产品呈现给你，效用函数迄今为止都是人类基于对他们的效用而强加的。

现有的深度学习系统依赖于已经分类的海量数据。给定一个大的数据集，机器有可能“训练”一个神经网络来优化它正确分类新例子的能力。这样的系统一旦被训练，就没有时刻记忆。如果你问 Alpha Go 它以前下过什么棋，它也不知道。它没有对过去事件的记忆，也没有对未来的计划。它只是根据通过玩数百万个游戏训练的神经网络一步一步地行动。它缺乏时间意识。

虽然深度学习神经网络已经被证明是有效的，但它们一旦部署就无法学习。训练机制在数据中心内的大规模并行矩阵计算机上运行。例如，谷歌使用深度学习技术来训练神经网络理解语音，然后部署到手机上。但是一旦上了你的手机，它就不会继续学习了。它不会适应你的具体发言。

这些现代神经网络的另一个特点是它们是串行的。一个图像输入，一个结果输出。一个音进去，一个句子出来。每个都是全新的，贯穿整个网络。没有从一个时刻到下一个时刻的状态存储。不存在将一层的输出反馈到前一层的环回。一幅图像的结果不会影响下一幅图像的结果。

我们正在失去短时的上下文记忆。在真实的大脑中，既有前馈神经通路，也有反馈神经通路。例如，控制眼睛的运动神经元也连接到视觉输入，这使我们能够毫不费力地跟踪移动的物体。这种反馈结构不仅存在于输入和输出之间，而且存在于所有层次之间。

更重要的是，这种反馈机制似乎是我们对世界的期望的核心。反馈系统允许我们进行内部模拟。如果模拟与观察到的世界一致，我们就高兴，但是如果模拟与观察到的现实有偏差，我们的大脑就会活跃起来，我们的意识就会注意到这种差异。意识本身似乎是一种神经反馈，其中一个思想的输出在源源不断的思想流中输入到下一个。

这种反馈机制被用来加强记忆，通过回放短期记忆，我们加强了神经连接，从而使它们成为长期记忆。众所周知，重复某件事会把它烧进你的大脑。无论是在现代教育系统中被如此诋毁的“死记硬背”还是武术的重复，这种重复的方法都会加强你的神经通路。已经证明，简单地做梦或思考训练可以像实际的体育训练一样提高技术。

在我看来，意识只是这个模拟过程的运行。有些动物，如蚂蚁，本质上是机器人。他们没有意识、意图或记忆的能力。但是狗或其他哺乳动物有更高级的学习大脑。学习、意识和记忆似乎都是紧密相连的，是同一事物的不同方面。它们是实时训练我们神经网络的反馈回路的结果。那么，我们如何着手建立一个展示这些特征的人工系统呢？

也许首先要理解的是，大脑是一个如何不断学习的系统；在训练阶段和它的使用之间没有人为的分离，就像现在的机器学习一样。学习是修改神经元权重的过程，从而修改网络的行为。短期记忆似乎更像是大脑中电活动的驻波。

这种观点认为，意识只是短期记忆和反馈循环。和我们住在一起的婆婆患有老年痴呆症，现在无法形成记忆。结果，她不再能形成或保持意愿。这实际上意味着她不能完成基本的任务，比如养活自己。这并不是身体上的缺陷，因为她仍然可以操纵物体，但是不能记得每时每刻她在做什么。

同样缺乏短期记忆的婴儿会是什么样子？它不仅会影响你保留环境中重要信息的能力，还会影响你形成持久意图的能力。你的短期内部记忆回放经验或想法，以加强神经连接，从而学习。类似的策略现在正在机器学习中使用，其中模拟用于生成新的训练数据。一个例子是 AlphaGo Zero，这是一种新的围棋人工智能，它不使用任何人类游戏数据，而是通过自己下棋来学习。

当前学习系统的方法是使用某种确定性效用函数来确定正确的行为。对于任何实施类似于人类的广泛奖励制度的系统来说，机器最大限度地提高回形针产量的反乌托邦未来显然是幻想。人类最初有着与生俱来的奖励，比如味觉。如果你把东西放进嘴里，它尝起来很好，你会做更多你刚刚做的事情。其他情绪，如恐惧和愤怒，是由感知到危险时释放的化学物质驱动的。化学物质的释放是对感知到的威胁和回报的习得性反应。

饥饿也是一样，如果你饿了，你就会有动力去寻找食物。因此，情绪是强大的内在意图发生器。

一些动物可能仅仅依靠这些较低层次的情感驱动力来直接控制它们的行为。然而，情绪似乎是训练大脑和驾驶行为的机制。人们记住创伤性事件而忘记日常事件是有原因的。有一种选择性的压力，去记住那些你将来可能想要避免的不好的事情，或者去记住那些令人愉快的事情，这样你就可以重复它们。在这种情况下，很容易看出影响大脑奖赏系统的药物是如何训练大脑继续吸食毒品的。

然而，仅仅是基本情绪并不能解释人类思维和创新的奇妙复杂性。也许我们调节大脑，使某些行为有其自身的回报，即使没有直接的物质回报。学习新事物能带来满足感和成就感，这种满足感和成就感独立于通常与快乐相关的任何物理刺激。

涉及物理刺激的简单方法不足以驱动需要高级计划和意图的复杂行为。例如，花几年时间在大学获得学位将需要几年的努力。如果没有内部奖励机制和持续的目标，这种长期计划是不可能的。这将倾向于表明，对于机器，我们可以从相对简单的感觉奖励系统开始，但需要有一种方法来修改神经网络如何发展受到奖励。

人类似乎在另外两个方面得到了回报。首先是沟通。显然，交流并不是人类独有的，许多物种都发展出了口头暗示和肢体语言来与家人交流环境中的危险。然而，没有其他动物像人类一样发展出复杂的象征性抽象语言能力。

一旦我们有了记忆和意图，下一步就是向他人传达意图。这使我们能够合作实现集体计划。人类部落主义和社区是我们的关键。积极的选择压力意味着人类渴望归属，渴望不孤独，渴望被我们的社区所接受。

理解情绪及其在训练自然神经网络中所起的作用，对于跨越深度学习系统和更自然的方法之间的差距至关重要，深度学习系统利用算法分析，而更自然的方法允许神经网络实时开发自己的奖励系统。

毫无疑问，深度学习将继续得到发展，并应用于许多应用。例如，我们真的不需要完全智能的人工智能来驾驶我们的汽车。如果有很会开车的窄 AI 就更好了。但是，为了实现真正的人类智能，我们可能需要等待一个利用更自然的反馈方法来强化的系统，以及一个模拟我们看到的与情感的化学相互作用的系统。