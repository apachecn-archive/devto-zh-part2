# 在边缘上运行分析

> 原文：<https://dev.to/michaelgv/running-on-the-edge-analysis-1hj8>

在[我的上一篇文章](https://dev.to/michaelgv/what-are-your-thoughts-on-running-code-at-the-edge-4kp8)之后，我们陷入困境，并一直在边缘进行测试，我们是这样做的:

我们开始部署边缘服务器，我们最大的问题是关于数据同步，我们希望有一个系统，边缘用户可以互动，张贴数据而不会丢失。我们使用一个专有工具来保持同步，但我们的第一个原型是没有 rowids 的 SQLite，redis 用于对消息进行排队——每个边缘节点都在运行这个工具，我们将它作为真实的来源。edge 将每半小时向后端服务器发送一次，我们将获得 rowids，并将我们的数据库与主服务器同步。

它工作了，但是我们遇到了一个大难题:我们的主人正在分配与边冲突的 rowids 通过放弃对 rowids 的依赖，并使用一个新的唯一令牌(UUID)，格式类似于:edge node-LOC-NNLL-{ rand x 8 }-{ dmy his }，它工作得很好，并有助于减少冲突。

我们接下来想解决漂亮的 URL 地址的问题，我们选择基于一些属性创建独特的 slugs(例如:section-title-NNLL)，这给了我们这样的 URL:/admin/content-editor/page/example-page-43ax

最后，保持我们所有的优势同步:我们选择了一个非标准的战略:

大师会推拉

节点(主机)可以推和拉，仅限于受信任的节点列表和密钥认证

边缘可以拉，但不能推，除非推给服务器“群”中的其他边缘

## 潜伏期

对于我们的测试版用户，我们将平均响应时间从 230 毫秒降低到了 43 毫秒——这是一个巨大的进步，依赖于这一速度的客户对此非常感激

## 负反馈

像所有产品一样，我们得到了一些负面反馈，最大的是我们的交付周期，以保持优势更新。我们在 LXD、多克和库伯内特身上下了很大功夫。我们保留 Kubernetes 作为我们的缓存优势，并直接使用 docker 和 lxd 来交付应用程序。

我们决定部署 Kubernetes 和*配置滚动更新*，并使我们的发布周期变得平稳——在配置方面有一些古怪——但那是另一篇文章！

*附注:我们将在 Dev* 上发布每周更新